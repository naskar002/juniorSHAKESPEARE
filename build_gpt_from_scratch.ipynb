{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkJQJsoiyeP6",
        "outputId": "7a854bf0-dd88-4011-d671-66e2a98540d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-13 03:50:21--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘/content/data/input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-03-13 03:50:21 (16.9 MB/s) - ‘/content/data/input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#download the data from internet using !wget\n",
        "!wget -P /content/data/ https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/data/input.txt','r',encoding = 'utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "GQgzD9BJzI5h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"length of chars: {len(text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-k8ajTy6KWU",
        "outputId": "f6191256-c7e7-4bfa-e567-054f42f80c1e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of chars: 1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZYjm5gr6W3L",
        "outputId": "ea2ce160-6c57-49f8-a7ff-d40c94a370fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a mapping from chars to integer\n",
        "stoi = {s:i for i,s in enumerate(chars)}\n",
        "itos={i:s for s,i in stoi.items()}\n",
        "#encoder -> take a string and o/p list of integers\n",
        "encoder = lambda s: [stoi[c] for c in s]\n",
        "decoder = lambda l:''.join([itos[i] for i in l])\n",
        "print(encoder(\"hi sneha\"))\n",
        "print(decoder(encoder(\"hi sneha\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dudnEDsr6xq_",
        "outputId": "273bbdc8-5592-469d-8438-0a69e84ba804"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 1, 57, 52, 43, 46, 39]\n",
            "hi sneha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encode the entire text dataset and store it into the torch tensor\n",
        "import torch\n",
        "data = torch.tensor(encoder(text),dtype = torch.long)\n",
        "print(data.shape,data.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34YWOfoV9jAZ",
        "outputId": "d8d7c975-57cd-4a7f-e466-115e1bbf0e6e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tran test split\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "test_data = data[n:]"
      ],
      "metadata": {
        "id": "LjjDy2zN-yWb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RdtBU7p_dcF",
        "outputId": "2a97aea3-bc8f-4677-c091-1a76ef659fa9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "x,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3D8wj7JAfXP",
        "outputId": "4e67ccd9-ddcb-4ddf-b6e1-b5c9f1d03dfd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([18, 47, 56, 57, 58,  1, 15, 47]),\n",
              " tensor([47, 56, 57, 58,  1, 15, 47, 58]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"context: {context} and target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH3BIZDl_yhw",
        "outputId": "e49acf09-3018-443c-dcc9-e9d4b61560e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context: tensor([18]) and target: 47\n",
            "context: tensor([18, 47]) and target: 56\n",
            "context: tensor([18, 47, 56]) and target: 57\n",
            "context: tensor([18, 47, 56, 57]) and target: 58\n",
            "context: tensor([18, 47, 56, 57, 58]) and target: 1\n",
            "context: tensor([18, 47, 56, 57, 58,  1]) and target: 15\n",
            "context: tensor([18, 47, 56, 57, 58,  1, 15]) and target: 47\n",
            "context: tensor([18, 47, 56, 57, 58,  1, 15, 47]) and target: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = torch.randint(3,10,(4,))\n",
        "num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5gRuUSNCBzK",
        "outputId": "013f5471-7c40-49c7-b02c-5659041819f1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 4, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch_size of 4 i.e. feed 4 rows of bolcksize\n",
        "torch.manual_seed(1337)\n",
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == \"train\" else test_data\n",
        "    ix = torch.randint(len(data)-block_size,(batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size]for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x,y\n",
        "\n",
        "x,y = get_batch('train')\n",
        "print('inputs: ')\n",
        "print(x.shape)\n",
        "print(x)\n",
        "print('targets: ')\n",
        "print(y.shape)\n",
        "print(y)\n",
        "\n",
        "print('-------'*10)\n",
        "\n",
        "for b in range(batch_size):\n",
        "    for t in range(block_size):\n",
        "        context = x[b, :t+1]\n",
        "        target = y[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q70b1LnhAtcK",
        "outputId": "eca93e65-9c44-4210-d329-23f9fe1fb34c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs: \n",
            "torch.Size([4, 8])\n",
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
            "targets: \n",
            "torch.Size([4, 8])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
            "----------------------------------------------------------------------\n",
            "when input is [24] the target: 43\n",
            "when input is [24, 43] the target: 58\n",
            "when input is [24, 43, 58] the target: 5\n",
            "when input is [24, 43, 58, 5] the target: 57\n",
            "when input is [24, 43, 58, 5, 57] the target: 1\n",
            "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
            "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
            "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
            "when input is [44] the target: 53\n",
            "when input is [44, 53] the target: 56\n",
            "when input is [44, 53, 56] the target: 1\n",
            "when input is [44, 53, 56, 1] the target: 58\n",
            "when input is [44, 53, 56, 1, 58] the target: 46\n",
            "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
            "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
            "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52] the target: 58\n",
            "when input is [52, 58] the target: 1\n",
            "when input is [52, 58, 1] the target: 58\n",
            "when input is [52, 58, 1, 58] the target: 46\n",
            "when input is [52, 58, 1, 58, 46] the target: 39\n",
            "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
            "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
            "when input is [25] the target: 17\n",
            "when input is [25, 17] the target: 27\n",
            "when input is [25, 17, 27] the target: 10\n",
            "when input is [25, 17, 27, 10] the target: 0\n",
            "when input is [25, 17, 27, 10, 0] the target: 21\n",
            "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
            "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
            "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VttmLhMzC-b7",
        "outputId": "9be40c1d-e9d0-4a1e-e267-1c377001a573"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self,vocab_size):\n",
        "        super().__init__()\n",
        "        #each ele in vocab will have dim of vocab size -> the prob of generate the next chars among all the chars\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
        "\n",
        "    def forward(self,idx,targets = None):\n",
        "        #idx dim : (Batch,Time)\n",
        "        logits = self.token_embedding_table(idx) #-> batch,time,channel\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B,T,C = logits.shape\n",
        "            logits = logits.view(B*T,C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits,targets)\n",
        "\n",
        "        return logits,loss\n",
        "\n",
        "    def generate(self,idx,max_new_tokens):\n",
        "        #idx is (B,T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #prediction\n",
        "            logits,loss = self(idx)\n",
        "            #get the logits of the last time step, this is the prediction for the next token\n",
        "            logits = logits[:, -1, :]  #(B, C)\n",
        "            #apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) #(B, C)\n",
        "            #sample from the distribution to get next token\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) #(B, 1)\n",
        "            #concatenate the new token to the input sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) #(B, T+1)\n",
        "        return idx\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits,loss = m(x,y)\n",
        "print(logits.shape)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwW3bQcrEzuP",
        "outputId": "905872b5-b839-4fa6-92b1-66ddf977a98e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.8786, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDE2We6-dgtZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWlAGIxwWYWn",
        "outputId": "068844d8-25ce-4cb2-b8d5-06afd92d2d22"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder(m.generate(idx=torch.zeros((1,1),dtype = torch.long),max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYttT4vrXdDB",
        "outputId": "6a36bacc-408f-46bd-a019-f40e050e3d8b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "pdcbf?pGXepydZJSrF$Jrqt!:wwWSzPNxbjPiD&Q!a;yNt$Kr$o-gC$WSjJqfBKBySKtSKpwNNfyl&w:q-jluBatD$Lj;?yzyUca\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create pytorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(),lr= 1e-3)"
      ],
      "metadata": {
        "id": "bvE1cbtTZp-P"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(1000):\n",
        "    x,y = get_batch('train')\n",
        "    logits,loss = m(x,y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm4bIq7EaZ3N",
        "outputId": "ce6117c3-bdd4-45ef-e28f-455f261d57c2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0705056190490723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYQ14jkWerdh",
        "outputId": "33d8fec0-63e3-46a0-b861-efb1ec95cf24"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "F bx-QJe.\n",
            "Qxcorea wstreA bi. pEse\n",
            "\n",
            "Glva EretLhMk,ep seay sVeARWWy, tUREENTbr ckXE3I&V&POnoi-s,Ioton vixcLInsiEl'dm C-.\n",
            "IOrPR\n",
            "IMI3fa hO ALIZveA kpre,\n",
            "\n",
            "PoBathZ;P?usev?ohoRiByENoy3B&jum.L; ik,\n",
            "FowayaKROn s\n",
            "WCIN.JU'ad; weOLAqVO:CoiBo? se I3Dor,ir.\n",
            "y\n",
            "OF r s mmyhist pZrAQll' ?YotezN\n",
            "BwowKo'sBqFoo?ppYenY uelk,-Z mdsa!wagmowens,SOLI:B-myce?nonstay,\n",
            "AywNodd  bGSonAlllleQnq-luHAUP.\n",
            "IANaongfI&xJUMAXEHE&DUFRSaiqFpre fasi.\n",
            "\n",
            "OfanXETIUCo,VzeChattR:CHYDINIUzUEO CE;hoTETWPratgrWhOEXEhaU'xx;\n",
            "pjJUTFOdZ-wolstetRy l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# self attention!\n",
        "torch.manual_seed(42)\n",
        "x = torch.rand((4,8,2))\n",
        "B,T,C = x.shape\n",
        "xbow = torch.zeros((B,T,C ))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        context = x[b,:t+1]\n",
        "        xbow[b,t] = torch.mean(context,0)"
      ],
      "metadata": {
        "id": "wsdh71KTe2Bk"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLbm_6HQqjtT",
        "outputId": "1e885dcf-e688-4f32-d371-3bcea27d3bda"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8823, 0.9150],\n",
              "        [0.6326, 0.9372],\n",
              "        [0.5519, 0.8251],\n",
              "        [0.4780, 0.8172],\n",
              "        [0.5706, 0.6804],\n",
              "        [0.6313, 0.6659],\n",
              "        [0.6653, 0.6519],\n",
              "        [0.6748, 0.6241]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 2 -> using matrix multiplication\n",
        "# final mat -> (T,C)\n",
        "wei = torch.tril(torch.ones(T,T))\n",
        "wei = wei/wei.sum(1,keepdim = True)\n",
        "xbow2 = wei @ x\n",
        "torch.allclose(xbow,xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkktL5p5qW32",
        "outputId": "eaa9e8f4-ed13-4717-c829-22759cd06857"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#version 3: using softmax\n",
        "tril = torch.tril(torch.ones(T,T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril ==0,float('-inf'))\n",
        "wei = F.softmax(wei,dim = -1)\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow,xbow3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0TNMQFbxiZ3",
        "outputId": "cbb35ff2-28f3-424b-b46a-889eefea95e2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#version 4: self attention\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "#single head attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C,head_size,bias = False)\n",
        "query = nn.Linear(C,head_size,bias = False)\n",
        "value = nn.Linear(C,head_size,bias = False)\n",
        "k = key(x)\n",
        "q = query(x)\n",
        "v = value(x) #output = (batch,seq,head_size)\n",
        "\n",
        "wei = (q @ k.transpose(-2,-1)*head_size**-0.5) #gives the raw interaction b/w the tokens\n",
        "tril = torch.tril(torch.ones(T,T))\n",
        "wei = wei.masked_fill(tril == 0,float('-inf')) #gives how much a particulat token depends on it and it's previous tokens\n",
        "wei = F.softmax(wei,dim = -1)\n",
        "out = wei @ v #(B,T,T) @ (B,T,16)\n",
        "out.shape\n",
        "out[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz3kAvGByOnD",
        "outputId": "30e01f5c-f00d-4145-8f01-580cd793ea90"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.5713e-01,  8.8009e-01,  1.6152e-01, -7.8239e-01, -1.4289e-01,\n",
              "          7.4676e-01,  1.0068e-01, -5.2395e-01, -8.8726e-01,  1.9068e-01,\n",
              "          1.7616e-01, -5.9426e-01, -4.8124e-01, -4.8599e-01,  2.8623e-01,\n",
              "          5.7099e-01],\n",
              "        [ 4.3974e-01, -1.4227e-01, -1.3157e-01,  2.8896e-03, -1.3222e-01,\n",
              "          6.6079e-04, -2.7904e-01, -2.2676e-01, -2.8723e-01,  5.7456e-01,\n",
              "          5.6053e-01, -2.5208e-01,  9.7243e-02,  1.0771e-01,  3.0455e-02,\n",
              "          1.0727e+00],\n",
              "        [ 4.3615e-01, -6.6358e-02, -2.9296e-01,  7.4315e-02,  5.4381e-02,\n",
              "         -7.0388e-02, -6.8985e-02, -8.2153e-02, -2.9377e-01, -5.8952e-02,\n",
              "          3.5887e-01, -2.3087e-03, -1.8212e-01, -3.6142e-02, -6.7189e-02,\n",
              "          1.1412e+00],\n",
              "        [ 4.2069e-01, -1.0619e-01, -2.9984e-01,  5.2820e-02,  2.0077e-01,\n",
              "         -1.6048e-01, -3.5710e-02, -8.3110e-02, -1.7919e-01,  7.7992e-02,\n",
              "          1.2719e-01,  2.2611e-02, -5.1811e-02,  7.4466e-02,  1.8131e-01,\n",
              "          8.4463e-01],\n",
              "        [ 3.9499e-01,  1.7130e-01,  5.1664e-02,  2.0128e-01,  2.4059e-01,\n",
              "          1.6471e-01,  1.9638e-01,  1.3151e-01, -3.0257e-01, -3.9997e-01,\n",
              "         -4.7060e-02, -6.8541e-02, -3.7259e-01,  1.4653e-01,  3.3643e-02,\n",
              "          7.8407e-01],\n",
              "        [ 3.2160e-01,  1.3167e-01,  3.4681e-02,  2.6722e-01,  2.1268e-01,\n",
              "          1.6392e-01,  1.1234e-01,  7.3362e-02, -2.4218e-01, -2.6597e-01,\n",
              "          2.2720e-02, -1.5014e-02, -2.8530e-01,  1.6292e-01,  7.6938e-02,\n",
              "          7.5743e-01],\n",
              "        [ 1.0560e-01,  4.5449e-02, -1.3713e-01,  2.3461e-01,  1.8927e-01,\n",
              "         -2.0829e-02, -4.4675e-02, -6.8756e-02, -1.2469e-01,  4.6523e-02,\n",
              "          1.0449e-01,  9.9329e-02, -1.0045e-02,  7.7849e-02,  1.9440e-01,\n",
              "          6.4730e-01],\n",
              "        [ 1.2431e-01,  4.5290e-02, -3.4119e-01,  2.7087e-01,  2.3352e-01,\n",
              "         -9.4792e-02, -4.2095e-02,  2.1426e-01, -3.2988e-02, -3.1300e-02,\n",
              "          5.1987e-02,  2.3780e-01,  1.0845e-01, -9.5935e-02,  2.9991e-02,\n",
              "          4.7065e-01]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQQ18FDREBDe",
        "outputId": "92c7659a-5fa6-4b57-c4af-8790c6f705f4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3966, 0.6034, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3069, 0.2892, 0.4039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3233, 0.2175, 0.2443, 0.2149, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1479, 0.2034, 0.1663, 0.1455, 0.3369, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1259, 0.2490, 0.1324, 0.1062, 0.3141, 0.0724, 0.0000, 0.0000],\n",
              "        [0.1598, 0.1990, 0.1140, 0.1125, 0.1418, 0.1669, 0.1061, 0.0000],\n",
              "        [0.0845, 0.1197, 0.1078, 0.1537, 0.1086, 0.1146, 0.1558, 0.1553]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2VXtfaLPE2Uv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}